= 可见性问题
:hp-tags: graphic

http://www.scratchapixel.com/lessons/3d-basic-rendering/rendering-3d-scene-overview/visibility-problem[原文出处]

在前一章节里，我们已经解释了什么事可见性问题。为了创建一个逼真的图像，我们需要从给定的观察点来决定一个对象的哪些部分是可见的。问题就是当我们按例去投影一个盒子的所有顶点，并且连接所有投影点绘制成盒子边，则盒子的所有面都是可见的。不管怎么说，真实情况下只有盒子的正面是可见的，其他面应该看不到。

在图形学中，解决可见性问题主要有两个方法：*光线追踪*和*栅格化*。我们会快速的解释他们是如何工作的。如今已很难搞清楚哪个方法更古老，只不过在图形学早期，栅格化更流行点。光线追踪比栅格化计算量大（使用内存多）是出了名的，比较下来会慢很多。以前的电脑也不快（内存也少），所以渲染图片基本不考虑使用光线追踪，至少在生产环境下如此（比如制作电影）。因此，几乎每个渲染器使用的都是栅格化（光线追踪一般仅限于研究项目）。但是，光线追踪在类似反射、柔和阴影等效果模拟上比栅格化好，原因我们下一章节解释。总的来说，用光线追踪比较容易创建逼真的图像，比起栅格化适用于渲染几何图形，光线追踪更适合模拟真实的着色和光阴效果。我们会在下一章节解释为什么。即时渲染API和显卡通畅使用栅格化，因为速度才是选择算法的决定因素。不过对于光线追踪的说法，80、90年代正确的，在今天就不一定是正确的。现如今电脑非常强大，光线追踪经常用于离线渲染器（至少，两种算法的混合方法已经被实现了）。为什么？还是因为对于模拟类似刺眼的光泽的反射，柔和的阴影等效果，光线追踪是最简单的方法。当速度不再是问题，那么在很多地方都比栅格化来的卓越（让光线追踪有效率的运作仍需要大量的工作）。Pixar的PhotoRealistic RenderMan，是Pixar开发的一个基于栅格化算法的渲染器（该算法被称为REYES，是Renders Everything You Ever Saw【渲染一切所见】的缩写，其构思深远，几乎是最好的可见面判定算法，连显卡的渲染管线都诸多类似REYES），制作过很多早期的电影(玩具总动员、海底总动员、虫虫特工队)。但目前Pixar的渲染器RIS是一个纯粹的光线追踪器。引入光线追踪使得工作室这几年内，极大的推动了写实化以及复杂图像的制作。

== 栅格化是如何解决可见性问题的？

我们已经把栅格化和光线追踪的区别清晰的解释过了（阅读上一章节）。让我们回顾一下，栅格化可以看作是，位于几何图形表面的一点P，沿着连接到眼睛的一条直线移动，直到碰到画布表面为止。当然，这条直线是隐藏的，实际上根本不需要去构造它，在此，我们是为了可以直观的去解释投影过程。

image::http://www.scratchapixel.com/images/upload/rendering-3d-scene-overview/projection3.png[caption="图1：", title="投影过程可以被看成是一个点沿着它和眼睛的连线一直向下移动，当碰到画布所在平面时停止移动。显然我们不必真的去滑动这个点，只是以此解释投影过程。", alt="投影过程"]

我们需要解决的是可见性问题。换句话说，在场景上可能会有很多点P,P1,P2等等，它们都投影在画布的同一点P'上（画布即是屏幕）。而在连接到眼睛的同一条直线上的所有点里，只有一个点能被摄影机看到，就是离眼睛最近的那个，参考图2.

image::http://www.scratchapixel.com/images/upload/rendering-3d-scene-overview/projection2.png[caption="图2：", title="场景上多个点可能会投影在屏幕的同一点上。摄影机能看到的是对齐的店中，离眼睛最近的那个点", alt="可见点"]

要解决可见性问题，首先要找出图中P'所在位置的表达式，即图像的像素坐标是什么，P'落在哪里？还记得投影一个点到画布表面，给定另一个点P'的实数坐标么。P'必须落在最终图像给定的像素上。因此，如何通过画布表面上一点P'的表达式，来定义其在最终图像上的位置（像素坐标）？这里涉及一个简单的坐标系变换。

* 首先定义的坐标系称为*屏幕空间*（或图像空间），其原点在画布中心。这个2D坐标系的所有轴都是单位长度（长度为1）。注意x或y轴上的点可以是负数，x轴向左以及向y轴向上即为负。

* 以格子形式定义的图片像素坐标系称为*栅格空间*，其原点通常位于图片的左上角，轴也是单位长度，一个像素为一单位长度。因此，画布在该坐标系中的实际尺寸由图片的垂直（高）和水平（宽）的维度决定（即像素表达式）。

image::http://www.scratchapixel.com/images/upload/rendering-3d-scene-overview/screentoraster.png[caption="图3：", title="计算一个画布上的点所处的像素值，需要把点从屏幕空间转换到NDC空间后，再从NDC空间转换到栅格空间。", alt="空间转换"]

将点从屏幕空间转换到栅格空间非常简单。因为在栅格空间中的点P'只会是正数，我们首先把P'归一化。换句话说，使其范围在0,1之间（当点被如此定义时，我们称点被定义在NDC空间中，NDC全称是Normalized Device Coordinates【归一设备空间】）。一旦转换到NDC空间，再把点转换到栅格空间就很简单了。只需乘以图片尺寸，然后四舍五入即可（像素坐标永远是整数）P'坐标的范围取决于屏幕中画布的尺寸。为了简单起见，假设画布的宽高都只有2个单位长度，也就是说P'在屏幕中的坐标范围是[-1,1]。以下是把P'坐标从屏幕空间转换到栅格空间的伪码：

[source,linenums]
int width = 64, height = 64; // 以像素为单位的图片尺寸
Vec3f P = Vec3f(-1, 2, 10); 
Vec2f P_proj; 
P_proj.x = P.x / P.z; // -0.1 
P_proj.y = P.y / P.z; // 0.2 
// 屏幕空间转换到归一空间
Vec2f P_proj_nor; 
P_proj_nor.x = (P_proj.x + 1) / 2; // (-0.1 + 1) / 2 = 0.45 
P_proj_nor.y = (1 - P_proj.y ) / 2; // (1 - 0.2) / 2 = 0.4 
// 最终转换到栅格空间
Vec2i P_proj_raster; 
P_proj_raster.x = (int)(P_proj_nor.x * width); 
P_proj_raster.y = (int)(P_proj_nor.y * height); 
if (P_proj_raster.x == width) P_proj_raster.x = width - 1; 
if (P_proj_raster.y == height) P_proj_raster.y = height - 1; 

代码中有一些东西需要注意。第一就是原点P，投影在屏幕空间和NDC空间的点，使用的是`Vec3f`和`Vec2f`类型，其坐标被定义为实数（浮点数）。然而最终落在栅格空间的点使用的是`Vec2i`类型，其坐标被定义为整数（图片的像素坐标）。数组在程序中从0开始，因此，在栅格空间中的坐标点永远不会大于图片宽度或者高度减去一。代码（14,15行）对其进行了检测并做了约束。同样，在NDC空间坐标原点位于图片的左下角，但是在栅格空间内原点位于左上角（见图3）。因此，坐标从NDC空间到栅格空间时需要反转。（代码8,9两行对此做了不同的检测）

但为何需要如此变换？解决可见性问题，要使用以下方法：

* 映射所有在屏幕上的点。
** 对每个映射点，都需要把P'从屏幕空间转换到栅格空间。

  来自读者的问题：“你说，映射屏幕上所有的点。如何才能找到这些点？”。这个问题非常好。从技术角度讲，我们可以把三角形或者多边形对象划分成很小的集合元素，使其投影到屏幕上时比不超过一个像素的大小。

** （利用栅格空间内的映射点）找到对应的像素点，把该点到眼睛的直线距离保存在一个特殊的列表中（深度列表）。
* 最后，按距离由小到大排序每个像素所维护的列表中所有的点。处理的结果很明显，对于图片上任何像素，可见的点就是列表中的第一个元素。

  需要排序列表的原因是，投影的顺序是不固定的。假设在列表顶部插入点，而在投影A点后，投影了一个比A点离眼睛更远的B点，那么此时B点就位于列表顶部了。所以排序是必须的。
  
基于这些的算法被称为*深度排序算法*。*对象深度的顺序（或者对象表面点的顺序）概念是所有栅格化算法的基础*。列举一些当今最有名的算法：

* z-buffering算法。这个算法应该是这种类别里最有名的了。我们之前讲过的REYES算法就实现了z-buffering算法。该算法在技术上非常类似于我们讲述过的对象表面的点，如何投影在屏幕上以及保存在深度列表中。
* 画家算法
* Newell算法
* ...(等待补充）

请记住这些似乎过时的玩意儿，所有的显卡都实现了某种z-buffer算法来生成图片。这些算法（至少是z-buffering）现今还是比较常见的。

....
当透明度
为什么我们需要维持一个点的列表？储存到眼睛最短距离的点就可以不需要这个列表。事实上，还可以做的更好：

* 对图片上每个像素，设置z为无穷大。
* 对场景上每个点。
** 投影后计算栅格化坐标。
** 如果当前点到眼睛的距离小于储存的距离，更新z。

你会发现，这和保存一个列表并排序的结果是一样的。那我们为何不这么做？因为这么做的前提是我们假设场景上所有的点都是完全透明的。一旦碰到半透明的情况会怎么样呢？显然，如果有半透明的点出现在同一个像素上，他们都可能会被看到。对此，就必须保存每个像素上所有的点，然后排序，利用特殊的混合算法（我们会在REYES算法课程里学到）计算出正确的像素值。
....